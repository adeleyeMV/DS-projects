{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling with Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Data wrangling with Spark SQL\") \\\n",
    "    .getOrCreate()\n",
    "path = \"data/sparkify_log_small.json\"\n",
    "user_log = spark.read.json(path)\n",
    "user_log.createOrReplaceTempView(\"user_log_table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which page did user id \"\"(empty string) NOT visit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "userId \"\" did not visit pages: ['Submit Downgrade', 'Downgrade', 'Logout', 'Save Settings', 'Settings', 'NextSong', 'Upgrade', 'Error', 'Submit Upgrade']\n"
     ]
    }
   ],
   "source": [
    "rows = spark.sql(\"\"\"\n",
    "                    SELECT DISTINCT ul1.page FROM user_log_table ul1\n",
    "                    LEFT ANTI JOIN (\n",
    "                        SELECT DISTINCT page FROM user_log_table\n",
    "                        WHERE user_log_table.userId = ''\n",
    "                    ) ul2 ON ul1.page = ul2.page\n",
    "                 \"\"\").collect()\n",
    "pages = [row.page for row in rows]\n",
    "print('userId \"\" did not visit pages: {}'.format(pages))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why might you prefer to use SQL over data frames? Why might you prefer data frames over SQL?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How many female users do we have in the data set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 462 female users\n"
     ]
    }
   ],
   "source": [
    "row = spark.sql(\"\"\"\n",
    "                    SELECT COUNT(DISTINCT(userId)) AS count FROM user_log_table\n",
    "                    WHERE gender='F'\n",
    "                 \"\"\").collect()\n",
    "count = row[0][0]\n",
    "print('There are {} female users'.format(count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How many songs were played from the most played artist?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83 songs were played from the most played artist: Coldplay\n"
     ]
    }
   ],
   "source": [
    "row = spark.sql(\"\"\"\n",
    "                    (SELECT artist, COUNT(song) AS count FROM user_log_table\n",
    "                    GROUP BY artist\n",
    "                    ORDER BY count DESC LIMIT 1)\n",
    "                 \"\"\").collect()\n",
    "count = row[0][0]\n",
    "print('{} songs were played from the most played artist: {}'.format(row[0][1], row[0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How many songs do users listen to on average between visiting our home page? Please round your answer to the closest integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|avg(count_results)|\n",
      "+------------------+\n",
      "| 6.898347107438017|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SELECT CASE WHEN 1 > 0 THEN 1 WHEN 2 > 0 THEN 2.0 ELSE 1.2 END;\n",
    "is_home = spark.sql(\"SELECT userID, page, ts, CASE WHEN page = 'Home' THEN 1 ELSE 0 END AS is_home FROM user_log_table \\\n",
    "            WHERE (page = 'NextSong') or (page = 'Home') \\\n",
    "            \")\n",
    "\n",
    "# keep the results in a new view\n",
    "is_home.createOrReplaceTempView(\"is_home_table\")\n",
    "\n",
    "# find the cumulative sum over the is_home column\n",
    "cumulative_sum = spark.sql(\"SELECT *, SUM(is_home) OVER \\\n",
    "    (PARTITION BY userID ORDER BY ts DESC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS period \\\n",
    "    FROM is_home_table\")\n",
    "\n",
    "# keep the results in a view\n",
    "cumulative_sum.createOrReplaceTempView(\"period_table\")\n",
    "\n",
    "# find the average count for NextSong\n",
    "spark.sql(\"SELECT AVG(count_results) FROM \\\n",
    "          (SELECT COUNT(*) AS count_results FROM period_table \\\n",
    "GROUP BY userID, period, page HAVING page = 'NextSong') AS counts\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
